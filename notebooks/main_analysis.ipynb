{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Risk and Return Prediction for E-commerce Products\n",
        "\n",
        "This notebook provides an interactive analysis of the risk and return prediction models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from src.kaggle_data_loader import load_kaggle_dataset\n",
        "from src.preprocessing import preprocess_data\n",
        "from src.models import train_multiple_models, RiskReturnPredictor\n",
        "from src.evaluation import (plot_confusion_matrix, plot_roc_curve, \n",
        "                           plot_feature_importance, plot_model_comparison,\n",
        "                           print_evaluation_summary)\n",
        "\n",
        "# Set style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load or Generate Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Kaggle dataset\n",
        "kaggle_path = '../data/raw/ecommerce_returns_kaggle.csv'\n",
        "df = load_kaggle_dataset(kaggle_path)\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Return rate: {df['returned'].mean():.2%}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore the dataset\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Return rate by category\n",
        "return_by_category = df.groupby('product_category')['returned'].mean().sort_values(ascending=False)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(return_by_category.index, return_by_category.values)\n",
        "plt.xlabel('Return Rate')\n",
        "plt.title('Return Rate by Product Category')\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Preprocess Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess for return prediction\n",
        "X_train, X_test, y_train, y_test, feature_names, scaler, label_encoders = \\\n",
        "    preprocess_data(df, target='returned', test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "print(f\"Features: {len(feature_names)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train multiple models\n",
        "results = train_multiple_models(X_train, X_test, y_train, y_test, feature_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print evaluation summary\n",
        "print_evaluation_summary(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "plot_model_comparison(results, metric='accuracy')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed analysis for best model\n",
        "best_model_name = max(results.keys(), key=lambda x: results[x]['metrics']['f1_score'])\n",
        "best_result = results[best_model_name]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(y_test, best_result['y_pred'], best_model_name, ax=axes[0])\n",
        "\n",
        "# ROC curve\n",
        "plot_roc_curve(y_test, best_result['y_pred_proba'], best_model_name, ax=axes[1])\n",
        "\n",
        "# Feature importance\n",
        "if best_result['feature_importance']:\n",
        "    plot_feature_importance(best_result['feature_importance'], best_model_name, \n",
        "                          top_n=15, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Risk Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess for risk prediction\n",
        "X_train_risk, X_test_risk, y_train_risk, y_test_risk, feature_names_risk, scaler_risk, label_encoders_risk = \\\n",
        "    preprocess_data(df, target='risk_level', test_size=0.2, random_state=42)\n",
        "\n",
        "# Train risk prediction model\n",
        "risk_predictor = RiskReturnPredictor(model_type='xgboost', random_state=42)\n",
        "risk_predictor.train(X_train_risk, y_train_risk)\n",
        "risk_metrics, y_pred_risk, y_pred_proba_risk = risk_predictor.evaluate(X_test_risk, y_test_risk)\n",
        "\n",
        "print(\"Risk Prediction Results:\")\n",
        "print(f\"  Accuracy:  {risk_metrics['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {risk_metrics['precision']:.4f}\")\n",
        "print(f\"  Recall:    {risk_metrics['recall']:.4f}\")\n",
        "print(f\"  F1-Score:  {risk_metrics['f1_score']:.4f}\")\n",
        "print(f\"  ROC-AUC:   {risk_metrics['roc_auc']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Make Predictions on New Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Predict on new samples\n",
        "sample_indices = np.random.choice(len(X_test), 10, replace=False)\n",
        "\n",
        "for idx in sample_indices:\n",
        "    return_prob = results[best_model_name]['predictor'].predict_proba(X_test.iloc[[idx]])[0, 1]\n",
        "    risk_prob = risk_predictor.predict_proba(X_test_risk.iloc[[idx]])[0, 1]\n",
        "    \n",
        "    print(f\"Sample {idx}: Return Probability = {return_prob:.2%}, Risk Probability = {risk_prob:.2%}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
